# Adapters Layer - Gu√≠a de Uso

Esta capa implementa el patr√≥n **Adapter** (parte de la Arquitectura Hexagonal) para desacoplar el c√≥digo de negocio de las implementaciones espec√≠ficas de servicios externos.

## üì¶ Estructura

```
adapters/
‚îú‚îÄ‚îÄ __init__.py                  # Exports principales
‚îú‚îÄ‚îÄ llm/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base.py                 # LLMAdapter interface (en core/interfaces.py)
‚îÇ   ‚îú‚îÄ‚îÄ openapi_adapter.py      # Implementaci√≥n OpenAI
‚îÇ   ‚îî‚îÄ‚îÄ example_usage.py        # Ejemplos de uso
‚îú‚îÄ‚îÄ messaging/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base.py                 # MessagingAdapter interface (en core/interfaces.py)
‚îÇ   ‚îî‚îÄ‚îÄ twilio_adapter.py       # Implementaci√≥n Twilio
‚îî‚îÄ‚îÄ storage/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ base.py                 # StorageAdapter interface
    ‚îú‚îÄ‚îÄ local_adapter.py        # Implementaci√≥n en memoria
    ‚îî‚îÄ‚îÄ example_usage.py        # Ejemplos de uso
```

## üéØ Interfaces Core

Las interfaces est√°n definidas en `src/core/interfaces.py`:

### `LLMAdapter`

Define el contrato para proveedores de LLM (Language Model):

```python
class LLMAdapter(ABC):
    @abstractmethod
    def get_agent_decision(
        self, user_text: str, context: ConversationContext | None = None
    ) -> AgentDecision:
        """Obtiene decisi√≥n estructurada del agente."""
        pass
    
    @abstractmethod
    def humanize_response(
        self, user_text: str, action: str, base_message: str, vehicles: list[dict] | None = None
    ) -> str:
        """Humaniza una respuesta estructurada."""
        pass
    
    @abstractmethod
    def generate_financing_response(self, user_text: str, vehicle_price: float) -> str:
        """Genera opciones de financiamiento."""
        pass
    
    @abstractmethod
    def generate_kavak_info_response(self, user_text: str, kavak_info: str, query: str) -> str:
        """Genera respuesta sobre informaci√≥n de Kavak."""
        pass
```

### `MessagingAdapter`

Define el contrato para sistemas de mensajer√≠a (WhatsApp, SMS, etc.):

```python
class MessagingAdapter(ABC):
    @abstractmethod
    def parse_webhook(self, event: dict) -> str:
        """Parsea webhook entrante."""
        pass
    
    @abstractmethod
    def send_message(self, message: str) -> str:
        """Env√≠a mensaje al usuario."""
        pass
```

### `StorageAdapter`

Define el contrato para almacenamiento de contexto de conversaci√≥n:

```python
class StorageAdapter(ABC):
    @abstractmethod
    async def get(self, session_id: str) -> ConversationContext | None:
        """Obtiene el contexto de una sesi√≥n."""
        pass
    
    @abstractmethod
    async def get_or_create(self, session_id: str) -> ConversationContext:
        """Obtiene o crea el contexto de una sesi√≥n."""
        pass
    
    @abstractmethod
    async def save(self, context: ConversationContext) -> None:
        """Guarda el contexto de una sesi√≥n."""
        pass
    
    @abstractmethod
    async def delete(self, session_id: str) -> bool:
        """Elimina el contexto de una sesi√≥n."""
        pass
    
    @abstractmethod
    async def exists(self, session_id: str) -> bool:
        """Verifica si existe una sesi√≥n."""
        pass
    
    @abstractmethod
    async def clear_all(self) -> int:
        """Elimina todas las sesiones."""
        pass
```

## üöÄ Uso de Adapters

### OpenAIAdapter (LLM)

### Importaci√≥n

```python
from src.adapters import OpenAIAdapter, get_default_openai_adapter
```

### Opci√≥n 1: Usar el adapter por defecto (recomendado)

```python
# Usa variables de entorno: OPENAI_API_KEY, OPENAI_API_BASE_URL
adapter = get_default_openai_adapter()

decision = adapter.get_agent_decision("Busco un Toyota Corolla 2023")
print(decision.action)  # AgentAction.SEARCH_CARS
```

### Opci√≥n 2: Configuraci√≥n custom

```python
adapter = OpenAIAdapter(
    api_key="sk-...",
    base_url="https://api.openai.com/v1",
    decision_model="gpt-4o-2024-08-06",  # Para decisiones estructuradas
    response_model="gpt-4o-mini"          # Para respuestas naturales
)
```

### Ejemplo completo con contexto

```python
from src.adapters import get_default_openai_adapter
from src.core.models import ConversationContext

# Inicializar adapter
adapter = get_default_openai_adapter()

# Crear contexto de conversaci√≥n
context = ConversationContext(session_id="user-123")
context.add_user_message("Busco un Toyota Corolla")

# Obtener decisi√≥n del agente
decision = adapter.get_agent_decision(
    user_text="Busco un Toyota Corolla 2023",
    context=context
)

# Humanizar respuesta
humanized = adapter.humanize_response(
    user_text="Busco un Toyota Corolla",
    action="search_cars",
    base_message="Encontr√© 5 veh√≠culos",
    vehicles=[{"make": "Toyota", "model": "Corolla", "year": 2023, "price": 350000}]
)

# Generar opciones de financiamiento
financing = adapter.generate_financing_response(
    user_text="¬øCu√°nto pagar√≠a al mes?",
    vehicle_price=350000.0
)

# Consultar informaci√≥n de Kavak
info = adapter.generate_kavak_info_response(
    user_text="¬øD√≥nde est√°n ubicados?",
    kavak_info="Informaci√≥n completa de Kavak...",
    query="ubicaciones"
)
```

### LocalStorageAdapter (Storage)

#### Importaci√≥n

```python
from src.adapters import LocalStorageAdapter
```

#### Uso b√°sico

```python
# Crear adapter con TTL de 10 minutos
adapter = LocalStorageAdapter(ttl_minutes=10)

# Obtener o crear sesi√≥n
context = await adapter.get_or_create("user-123")

# Agregar mensajes
context.add_user_message("Busco un Toyota Corolla")
context.add_assistant_message("Encontr√© 5 veh√≠culos")

# Guardar contexto
await adapter.save(context)

# Recuperar contexto
context = await adapter.get("user-123")

# Verificar existencia
exists = await adapter.exists("user-123")

# Eliminar sesi√≥n
deleted = await adapter.delete("user-123")

# Limpiar todas las sesiones
count = await adapter.clear_all()
```

#### Gesti√≥n de veh√≠culos en contexto

```python
from src.core.models import SelectedVehicle

adapter = LocalStorageAdapter(ttl_minutes=10)
context = await adapter.get_or_create("user-123")

# Guardar resultados de b√∫squeda
vehicles = [
    SelectedVehicle(
        stock_id=1001,
        make="Toyota",
        model="Corolla",
        year=2023,
        price=350000.0,
        km=15000
    ),
    SelectedVehicle(
        stock_id=1002,
        make="Honda",
        model="Civic",
        year=2023,
        price=380000.0,
        km=12000
    ),
]

context.set_search_results(vehicles)

# Seleccionar un veh√≠culo
success = context.select_vehicle_by_stock_id(1001)

# Guardar cambios
await adapter.save(context)
```

#### Limpieza de sesiones expiradas

```python
adapter = LocalStorageAdapter(ttl_minutes=10)

# Limpiar sesiones expiradas manualmente
cleaned = await adapter.cleanup_expired()
print(f"Limpiadas {cleaned} sesiones expiradas")

# Ver n√∫mero de sesiones activas
print(f"Sesiones activas: {adapter.session_count}")
```

#### Caracter√≠sticas de LocalStorageAdapter

- **Thread-safe**: Usa Lock para operaciones concurrentes
- **TTL configurable**: Expiraci√≥n autom√°tica de sesiones
- **Limpieza manual**: M√©todo `cleanup_expired()` para liberar memoria
- **Propiedades √∫tiles**: `session_count`, `ttl_minutes`
- **Async**: Todas las operaciones son async para consistencia

**Cu√°ndo usar:**
- ‚úÖ Desarrollo local
- ‚úÖ Testing
- ‚úÖ Prototipado r√°pido
- ‚úÖ Ambientes de baja escala

**NO recomendado para:**
- ‚ùå Producci√≥n de alta escala
- ‚ùå Ambientes distribuidos (m√∫ltiples instancias Lambda)
- ‚ùå Cuando se requiere persistencia entre reinicios

**Para producci√≥n, considera:** DynamoDB, Redis, o Elasticache

## üîÑ Migraciones

### Migraci√≥n desde `llm.client` (OpenAI)

#### Antes (acceso directo)

```python
from src.llm.client import (
    get_agent_decision,
    humanize_response,
    generate_financing_response,
    generate_kavak_info_response
)

decision = get_agent_decision("Busco un auto", context)
```

#### Despu√©s (con adapter)

```python
from src.adapters import get_default_openai_adapter

adapter = get_default_openai_adapter()
decision = adapter.get_agent_decision("Busco un auto", context)
```

### Migraci√≥n desde `agent.context` (Storage)

#### Antes (acceso directo)

```python
from src.agent.context import LocalContextStore

store = LocalContextStore(ttl_minutes=10)
context = await store.get_or_create("user-123")
context.add_user_message("Hola")
await store.save(context)
```

#### Despu√©s (con adapter)

```python
from src.adapters import LocalStorageAdapter

adapter = LocalStorageAdapter(ttl_minutes=10)
context = await adapter.get_or_create("user-123")
context.add_user_message("Hola")
await adapter.save(context)
```

**Nota:** `LocalStorageAdapter` es un drop-in replacement de `LocalContextStore`. 
La API es 100% compatible, solo cambia el import y el nombre de la clase.

## ‚úÖ Ventajas del Patr√≥n Adapter

1. **Desacoplamiento**: El c√≥digo de negocio no depende directamente de OpenAI
2. **Testabilidad**: F√°cil crear mocks del adapter para testing
3. **Intercambiabilidad**: Cambiar de proveedor (OpenAI ‚Üí Anthropic ‚Üí local model) sin tocar la l√≥gica
4. **Configurabilidad**: Diferentes configuraciones por ambiente (dev, prod)
5. **Dependency Injection**: Inyectar el adapter en servicios

## üß™ Testing con el Adapter

```python
from unittest.mock import Mock
from src.core.interfaces import LLMAdapter
from src.core.models import AgentAction, AgentDecision

def test_process_message():
    # Crear un mock del adapter
    mock_adapter = Mock(spec=LLMAdapter)
    mock_adapter.get_agent_decision.return_value = AgentDecision(
        action=AgentAction.SEARCH_CARS,
        make="Toyota",
        model="Corolla"
    )
    
    # Inyectar en tu servicio
    service = MyService(llm_adapter=mock_adapter)
    result = service.process("Busco un Toyota")
    
    # Verificar llamadas
    mock_adapter.get_agent_decision.assert_called_once()
```

## üîÆ Futuros Adapters

### LLM Adapters

#### AnthropicAdapter (Claude)

```python
class AnthropicAdapter(LLMAdapter):
    def __init__(self, api_key: str):
        self.client = anthropic.Anthropic(api_key=api_key)
    
    def get_agent_decision(self, user_text: str, context=None) -> AgentDecision:
        # Implementaci√≥n espec√≠fica de Claude
        pass
```

#### LocalLLMAdapter (Llama, Mistral)

```python
class LocalLLMAdapter(LLMAdapter):
    def __init__(self, model_path: str):
        self.model = load_local_model(model_path)
    
    def get_agent_decision(self, user_text: str, context=None) -> AgentDecision:
        # Implementaci√≥n para modelos locales
        pass
```

### Storage Adapters

#### DynamoDBStorageAdapter

```python
class DynamoDBStorageAdapter(StorageAdapter):
    """Adapter para almacenamiento en DynamoDB.
    
    Ideal para producci√≥n en AWS Lambda:
    - Serverless y escalable
    - Baja latencia
    - TTL nativo de DynamoDB
    - Integraci√≥n con IAM
    """
    
    def __init__(
        self,
        table_name: str,
        region: str = "us-east-1",
        ttl_minutes: int = 30
    ):
        self.dynamodb = boto3.resource('dynamodb', region_name=region)
        self.table = self.dynamodb.Table(table_name)
        self.ttl_minutes = ttl_minutes
    
    async def get(self, session_id: str) -> ConversationContext | None:
        response = self.table.get_item(Key={'session_id': session_id})
        if 'Item' not in response:
            return None
        return self._deserialize(response['Item'])
    
    async def save(self, context: ConversationContext) -> None:
        item = self._serialize(context)
        item['ttl'] = int((datetime.now() + timedelta(minutes=self.ttl_minutes)).timestamp())
        self.table.put_item(Item=item)
```

**Configuraci√≥n de tabla DynamoDB:**

```yaml
# template.yaml (SAM/CloudFormation)
ConversationTable:
  Type: AWS::DynamoDB::Table
  Properties:
    TableName: kavak-agent-conversations
    AttributeDefinitions:
      - AttributeName: session_id
        AttributeType: S
    KeySchema:
      - AttributeName: session_id
        KeyType: HASH
    BillingMode: PAY_PER_REQUEST
    TimeToLiveSpecification:
      AttributeName: ttl
      Enabled: true
```

#### RedisStorageAdapter

```python
class RedisStorageAdapter(StorageAdapter):
    """Adapter para almacenamiento en Redis/Elasticache.
    
    Ideal para:
    - Alta velocidad de lectura/escritura
    - Cache distribuido
    - Sesiones con TTL autom√°tico
    - Pub/Sub para eventos
    """
    
    def __init__(
        self,
        host: str = "localhost",
        port: int = 6379,
        password: str | None = None,
        ttl_seconds: int = 600,
        db: int = 0
    ):
        self.redis = redis.Redis(
            host=host,
            port=port,
            password=password,
            db=db,
            decode_responses=True
        )
        self.ttl_seconds = ttl_seconds
    
    async def get(self, session_id: str) -> ConversationContext | None:
        data = self.redis.get(f"session:{session_id}")
        if not data:
            return None
        return self._deserialize(json.loads(data))
    
    async def save(self, context: ConversationContext) -> None:
        key = f"session:{context.session_id}"
        data = json.dumps(self._serialize(context))
        self.redis.setex(key, self.ttl_seconds, data)
    
    async def clear_all(self) -> int:
        keys = self.redis.keys("session:*")
        if keys:
            return self.redis.delete(*keys)
        return 0
```

**Uso con Redis:**

```python
from src.adapters.storage import RedisStorageAdapter

# Desarrollo local
adapter = RedisStorageAdapter(
    host="localhost",
    port=6379,
    ttl_seconds=600
)

# Producci√≥n con Elasticache
adapter = RedisStorageAdapter(
    host="your-elasticache-endpoint.cache.amazonaws.com",
    port=6379,
    password=os.getenv("REDIS_PASSWORD"),
    ttl_seconds=1800  # 30 minutos
)
```

### Comparaci√≥n de Storage Adapters

| Caracter√≠stica | Local | DynamoDB | Redis |
|---------------|-------|----------|-------|
| **Persistencia** | ‚ùå En memoria | ‚úÖ Persistente | ‚ö†Ô∏è Persistente con backup |
| **Escalabilidad** | ‚ùå Single instance | ‚úÖ Serverless | ‚úÖ Cluster |
| **Latencia** | ‚ö° Sub-ms | üöÄ 1-5 ms | ‚ö° Sub-ms |
| **TTL nativo** | ‚úÖ Manual | ‚úÖ Autom√°tico | ‚úÖ Autom√°tico |
| **Costo** | üí∞ Gratis | üí∞üí∞ Por request | üí∞üí∞üí∞ Por hora |
| **Complejidad** | Simple | Media | Media |
| **AWS Lambda** | ‚ö†Ô∏è No distribuido | ‚úÖ Ideal | ‚úÖ Con VPC |
| **Uso recomendado** | Dev/Test | Producci√≥n AWS | High-perf cache |

## üìù Notas de Implementaci√≥n

### Cach√© del Cliente

El adapter usa `@lru_cache` para cachear la instancia por defecto:

```python
@lru_cache(maxsize=1)
def get_default_openai_adapter() -> OpenAIAdapter:
    return OpenAIAdapter()
```

Esto garantiza que solo se cree una instancia del cliente OpenAI durante la ejecuci√≥n.

### Modelos Configurables

El adapter usa dos modelos:
- **decision_model** (`gpt-4o-2024-08-06`): Para structured outputs (decisiones)
- **response_model** (`gpt-4o-mini`): Para respuestas naturales (m√°s r√°pido y econ√≥mico)

### Construcci√≥n de Contexto

El adapter incluye m√©todos privados para formatear el contexto:
- `_build_messages_with_context()`: Construye array de mensajes para OpenAI
- `_format_context_info()`: Formatea informaci√≥n de contexto (b√∫squedas previas, veh√≠culo seleccionado)

## üéì Recursos

- [Arquitectura Hexagonal](https://alistair.cockburn.us/hexagonal-architecture/)
- [Adapter Pattern](https://refactoring.guru/design-patterns/adapter)
- [OpenAI Python SDK](https://github.com/openai/openai-python)
- [Dependency Injection in Python](https://python-dependency-injector.ets-labs.org/)

## ü§ù Contribuir

Para agregar un nuevo adapter:

1. Crear nueva clase que herede de `LLMAdapter` o `MessagingAdapter`
2. Implementar todos los m√©todos abstractos
3. Agregar tests unitarios
4. Actualizar exports en `__init__.py`
5. Documentar el uso en este README

